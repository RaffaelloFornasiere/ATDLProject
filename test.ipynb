{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet_v2 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "print(tf.__version__)\n",
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       Id                                            Caption\n0  000001  pericardial tamponade with clear distinction o...\n1  000002  angiography of the aortic arch show delay visu...\n2  000003  balloonocclude retrograde transvenous oblitera...\n3  000004  film after glue embolization show no filling i...\n4  000005  peripheral in posteroanterior projection angio...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000001</td>\n      <td>pericardial tamponade with clear distinction o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000002</td>\n      <td>angiography of the aortic arch show delay visu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000003</td>\n      <td>balloonocclude retrograde transvenous oblitera...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000004</td>\n      <td>film after glue embolization show no filling i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000005</td>\n      <td>peripheral in posteroanterior projection angio...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts_path = 'data/caption_prediction_train.csv'\n",
    "\n",
    "df_captions = pd.read_csv(concepts_path, sep=';', names=['Id', 'Caption'])\n",
    "df_captions['Id'] = df_captions['Id'].str[-6:]\n",
    "captions = df_captions.to_numpy()\n",
    "np.save('data/captions.npy', captions)\n",
    "df_captions.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_numpy(in_dir, out_dir, filename_transform=None):\n",
    "    ids = []\n",
    "    for filename in tqdm(os.listdir(in_dir)):\n",
    "        if (filename.endswith(\".jpg\")):\n",
    "            image = cv2.imread(filename=os.path.join(in_dir, filename), flags=cv2.IMREAD_COLOR)\n",
    "            if image.shape != (128, 128, 3):\n",
    "                print('Error')\n",
    "            filename = filename[:-4]\n",
    "            if filename_transform:\n",
    "                filename = filename_transform(filename)\n",
    "            assert len(filename) == 6\n",
    "            np.save(os.path.join(out_dir, filename), np.array(image))\n",
    "            ids.append(filename)\n",
    "    return ids\n",
    "\n",
    "\n",
    "transform = lambda x: x.split('_')[-1]\n",
    "\n",
    "train_dir = 'data/train/'\n",
    "val_dir = 'data/validation/'\n",
    "test_dir = 'data/test/'\n",
    "train_numpy_dir = 'data/numpy/train/'\n",
    "val_numpy_dir = 'data/numpy/validation/'\n",
    "test_numpy_dir = 'data/numpy/test/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67842/67842 [00:28<00:00, 2419.30it/s]\n",
      "100%|██████████| 7983/7983 [00:00<00:00, 2927358.70it/s]\n",
      "100%|██████████| 7452/7452 [00:02<00:00, 2512.20it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ids = []\n",
    "val_ids = []\n",
    "test_ids = []\n",
    "if os.path.exists(train_numpy_dir) and len(os.listdir(train_numpy_dir)) == len(os.listdir(train_dir)):\n",
    "    in_dir = train_numpy_dir\n",
    "    for filename in tqdm(os.listdir(in_dir)):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            train_ids.append(filename[:-4])\n",
    "else:\n",
    "    in_dir = train_numpy_dir\n",
    "    for f in os.listdir(in_dir):\n",
    "        if os.path.exists(os.path.join(in_dir, f)):\n",
    "            os.remove(os.path.join(in_dir, f))\n",
    "    train_ids = convert_to_numpy(train_dir, train_numpy_dir, transform)\n",
    "\n",
    "if os.path.exists(val_numpy_dir) and len(os.listdir(val_numpy_dir)) == len(os.listdir(val_dir)):\n",
    "    in_dir = val_numpy_dir\n",
    "    for filename in tqdm(os.listdir(in_dir)):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            val_ids.append(filename[:-4])\n",
    "else:\n",
    "    in_dir = val_numpy_dir\n",
    "    for f in os.listdir(in_dir):\n",
    "        if os.path.exists(os.path.join(in_dir, f)):\n",
    "            os.remove(os.path.join(in_dir, f))\n",
    "    val_ids = convert_to_numpy(val_dir, val_numpy_dir, transform)\n",
    "\n",
    "if os.path.exists(test_numpy_dir) and len(os.listdir(test_numpy_dir)) == len(os.listdir(test_dir)):\n",
    "    in_dir = test_numpy_dir\n",
    "    for filename in tqdm(os.listdir(in_dir)):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            test_ids.append(filename[:-4])\n",
    "else:\n",
    "    in_dir = test_numpy_dir\n",
    "    for f in os.listdir(in_dir):\n",
    "        if os.path.exists(os.path.join(in_dir, f)):\n",
    "            os.remove(os.path.join(in_dir, f))\n",
    "    test_ids = convert_to_numpy(test_dir, test_numpy_dir, transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "\n",
    "captions_train = captions[:len(train_ids)]\n",
    "captions_val = captions[len(train_ids):len(train_ids) + len(val_ids)]\n",
    "captions_test = captions[len(train_ids) + len(val_ids):]\n",
    "train_ids.sort()\n",
    "val_ids.sort()\n",
    "test_ids.sort()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "for i in range(len(captions_train)):\n",
    "    if captions_train[i][0] != train_ids[i]:\n",
    "        print(captions_train[i][0], train_ids[i])\n",
    "    assert captions_train[i][0] == train_ids[i]\n",
    "\n",
    "for i in range(len(captions_val)):\n",
    "    if captions_val[i][0] != val_ids[i]:\n",
    "        print(captions_val[i][0], val_ids[i])\n",
    "    assert captions_val[i][0] == val_ids[i]\n",
    "\n",
    "for i in range(len(captions_test)):\n",
    "    if captions_test[i][0] != test_ids[i]:\n",
    "        print(captions_test[i][0], test_ids[i])\n",
    "    assert captions_test[i][0] == test_ids[i]\n",
    "\n",
    "captions_train = np.array(captions_train[:, 1])\n",
    "captions_val = np.array(captions_val[:, 1])\n",
    "captions_test = np.array(captions_test[:, 1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Lambda\n",
    "\n",
    "tfds.disable_progress_bar()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Embedding size for each token\n",
    "embed_dim = 512\n",
    "# Dimention of the latent space\n",
    "latent_dim = 1024\n",
    "# Number of attention heads\n",
    "num_heads = 4\n",
    "sequence_length = 512\n",
    "vocab_size = 20000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def project_embeddings(\n",
    "    embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "):\n",
    "    projected_embeddings = tfkl.Dense(units=projection_dims)(embeddings)\n",
    "    for _ in range(num_projection_layers):\n",
    "        x = tf.nn.gelu(projected_embeddings)\n",
    "        x = tfkl.Dense(projection_dims)(x)\n",
    "        x = tfkl.Dropout(dropout_rate)(x)\n",
    "        x = tfkl.Add()([projected_embeddings, x])\n",
    "        projected_embeddings = tfkl.LayerNormalization()(x)\n",
    "    return projected_embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def build_resnet(size_embedding):\n",
    "    # Load the ResNet50 model with pre-trained weights\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "    # Freeze the layers in the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add a GlobalAveragePooling2D layer\n",
    "    inputs = tfkl.Input(shape=(224, 224, 3), name=\"image_input\")\n",
    "    embeddings = base_model(inputs)\n",
    "    embeddings = tfkl.GlobalAveragePooling2D()(embeddings)\n",
    "    output = tfkl.Dense(size_embedding, activation='relu')(embeddings)\n",
    "\n",
    "    # Build the ResNet50 model\n",
    "    resnet = Model(inputs=inputs, outputs=output)\n",
    "    resnet.summary()\n",
    "\n",
    "    return resnet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(tfkl.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Embedding layer for the token\n",
    "        self.token_emb = tfkl.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        # Embedding layer for the position\n",
    "        self.pos_emb = tfkl.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Find the maximum length of the input\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        # Create a tensor with positions from 0 to maxlen-1\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        # Embed the positions\n",
    "        positions = self.pos_emb(positions)\n",
    "        # Embed the tokens\n",
    "        x = self.token_emb(x)\n",
    "        # Add the token and position embeddings\n",
    "        return x + positions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(tfkl.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.att = tfkl.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tfk.Sequential(\n",
    "            [\n",
    "                tfkl.Dense(ff_dim, activation=\"relu\"),\n",
    "                tfkl.Dense(embed_dim)\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = tfkl.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tfkl.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tfkl.Dropout(rate)\n",
    "        self.dropout2 = tfkl.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        # Self-attention\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        # Apply dropout to the attention output\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        # Add the attention output to the input and normalize\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        # Feed-forward\n",
    "        ffn_output = self.ffn(out1)\n",
    "        # Apply dropout to the feed-forward output\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        # Add the feed-forward output to the previous output and normalize\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import keras_nlp as nlp\n",
    "def build_encoder():\n",
    "    encoder_inputs = tfk.Input(shape=(512), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "    # Adding token and position embedding layer\n",
    "    x = nlp.layers.TokenAndPositionEmbedding(vocab_size, sequence_length, embed_dim)(encoder_inputs)\n",
    "    # Adding transformer encoder block\n",
    "    encoder_outputs = TransformerEncoderBlock(embed_dim, num_heads, latent_dim)(x)\n",
    "\n",
    "    # compute the mean of the non-masked embeddings\n",
    "    pooled_output = tf.reduce_mean(encoder_outputs, axis=1)\n",
    "    print(pooled_output.shape)\n",
    "\n",
    "\n",
    "    #output = project_embeddings(pooled_output, 1, embed_dim, 0.1)\n",
    "\n",
    "    # Defining the encoder model\n",
    "    encoder = tfk.Model(encoder_inputs, pooled_output)\n",
    "    # Print the summary of the encoder model\n",
    "    encoder.summary()\n",
    "    # Visualize the encoder model\n",
    "    tfk.utils.plot_model(encoder)\n",
    "\n",
    "    return encoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def build_clip(resnet, transformer):\n",
    "    # Create the input layer\n",
    "    input_layer_transformer = Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "    input_layer_resnet = Input(shape=(128, 128, 3))\n",
    "\n",
    "    # Pass the input through the ResNet50 model\n",
    "    input_layer_resized = tfkl.Resizing(224, 224)(input_layer_resnet)\n",
    "    image_features = resnet(input_layer_resized)\n",
    "\n",
    "    # Pass the input through the Transformer model\n",
    "    text_features = transformer(input_layer_transformer)\n",
    "\n",
    "    print(text_features.shape)\n",
    "    print(image_features.shape)\n",
    "\n",
    "    joint_features = tf.concat([image_features, text_features], axis=1)\n",
    "\n",
    "\n",
    "    clip = Model(inputs=[input_layer_resnet, input_layer_transformer], outputs=joint_features)\n",
    "\n",
    "    return clip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,636,800\n",
      "Trainable params: 1,049,088\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the ResNet50 and Transformer models\n",
    "resnet = build_resnet(512)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 512)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_inputs (InputLayer)  [(None, 512)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, 512, 512)         10502144  \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer_encoder_block (  (None, 512, 512)         5253120   \n",
      " TransformerEncoderBlock)                                        \n",
      "                                                                 \n",
      " tf.math.reduce_mean (TFOpLa  (None, 512)              0         \n",
      " mbda)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,755,264\n",
      "Trainable params: 15,755,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "#Build encoder\n",
    "encoder = build_encoder()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 512)\n",
      "(None, 512)\n"
     ]
    }
   ],
   "source": [
    "clip = build_clip(resnet, encoder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " resizing_1 (Resizing)          (None, 224, 224, 3)  0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 512)          24636800    ['resizing_1[0][0]']             \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 512)          15755264    ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 1024)         0           ['model_1[0][0]',                \n",
      "                                                                  'model_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40,392,064\n",
      "Trainable params: 16,804,352\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "clip.summary()\n",
    "tfk.utils.plot_model(clip)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "#Loss function finally working!!\n",
    "from tensorflow.keras.losses import cosine_similarity\n",
    "\n",
    "def clip_loss_test(y_true, y_pred, temperature=0.1):\n",
    "\n",
    "    image_embeddings, caption_embeddings = tf.split(y_pred, num_or_size_splits=2, axis=1)\n",
    "\n",
    "    # logits[i][j] is the dot_similarity(caption_i, image_j).\n",
    "    logits = (\n",
    "        tf.matmul(caption_embeddings, image_embeddings, transpose_b=True)\n",
    "        / temperature\n",
    "    )\n",
    "    # images_similarity[i][j] is the dot_similarity(image_i, image_j).\n",
    "    images_similarity = tf.matmul(\n",
    "        image_embeddings, image_embeddings, transpose_b=True\n",
    "    )\n",
    "    # captions_similarity[i][j] is the dot_similarity(caption_i, caption_j).\n",
    "    captions_similarity = tf.matmul(\n",
    "        caption_embeddings, caption_embeddings, transpose_b=True\n",
    "    )\n",
    "    # targets[i][j] = avarage dot_similarity(caption_i, caption_j) and dot_similarity(image_i, image_j).\n",
    "    targets = tfk.activations.softmax(\n",
    "        (captions_similarity + images_similarity) / (2 * temperature)\n",
    "    )\n",
    "    # Compute the loss for the captions using crossentropy\n",
    "    captions_loss = tfk.losses.categorical_crossentropy(\n",
    "        y_true=targets, y_pred=logits, from_logits=True\n",
    "    )\n",
    "    # Compute the loss for the images using crossentropy\n",
    "    images_loss = tfk.losses.categorical_crossentropy(\n",
    "        y_true=tf.transpose(targets), y_pred=tf.transpose(logits), from_logits=True\n",
    "    )\n",
    "    # Return the mean of the loss over the batch.\n",
    "    return (captions_loss + images_loss) / 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = tfk.optimizers.Adam(learning_rate)\n",
    "metrics = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "class ClipDataLoader(tfk.utils.Sequence):\n",
    "    def __init__(self, list_IDs, captions, batch_size=32, dim=(128, 128, 3),\n",
    "                 shuffle=True, directory='data/train'):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.directory = directory\n",
    "        self.indexes = None\n",
    "        self.captions = captions\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"  # X : (n_samples, *dim)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.zeros(self.batch_size, dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load(os.path.join(self.directory + ID + '.npy'))\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        captions = self.captions.numpy()[indexes]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return (X, captions), y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "#Preprocessing of the data\n",
    "vectorization = tfkl.TextVectorization(\n",
    "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
    ")\n",
    "captions_train_vect = captions_train.copy()\n",
    "captions_val_vect = captions_val.copy()\n",
    "captions_test_vect = captions_test.copy()\n",
    "\n",
    "vectorization.adapt(np.append(captions_train_vect, captions_val_vect))\n",
    "captions_train_vect = vectorization(captions_train_vect)\n",
    "captions_val_vect = vectorization(captions_val_vect)\n",
    "captions_test_vect = vectorization(captions_test_vect)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "\n",
    "train_generator = ClipDataLoader(train_ids, captions_train_vect, batch_size=64, directory=train_numpy_dir)\n",
    "val_generator = ClipDataLoader(val_ids, captions_val_vect, batch_size=64, directory=val_numpy_dir)\n",
    "test_generator = ClipDataLoader(test_ids, captions_train_vect, batch_size=64, directory=test_numpy_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/0y/xb7crskj6j96cb2cmd4bsvm00000gn/T/ipykernel_48704/3730436055.py\", line 6, in <module>\n      history = clip.fit(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall'\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/0y/xb7crskj6j96cb2cmd4bsvm00000gn/T/ipykernel_48704/3730436055.py\", line 6, in <module>\n      history = clip.fit(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall'\n2 root error(s) found.\n  (0) NOT_FOUND:  could not find registered platform with id: 0x1116ff910\n\t [[{{node StatefulPartitionedCall}}]]\n\t [[gradient_tape/model_3/model_2/transformer_encoder_block/multi_head_attention/attention_output/add/Reshape/_84]]\n  (1) NOT_FOUND:  could not find registered platform with id: 0x1116ff910\n\t [[{{node StatefulPartitionedCall}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_62827]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[92], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m clip\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39moptimizer, loss\u001B[38;5;241m=\u001B[39mclip_loss_test, metrics\u001B[38;5;241m=\u001B[39mmetrics)\n\u001B[1;32m      3\u001B[0m EPOCHS \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[0;32m----> 6\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mclip\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mval_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mNotFoundError\u001B[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/0y/xb7crskj6j96cb2cmd4bsvm00000gn/T/ipykernel_48704/3730436055.py\", line 6, in <module>\n      history = clip.fit(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall'\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/0y/xb7crskj6j96cb2cmd4bsvm00000gn/T/ipykernel_48704/3730436055.py\", line 6, in <module>\n      history = clip.fit(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/forna/Documents/1.Politecnico/ATDL/ATDLproject/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall'\n2 root error(s) found.\n  (0) NOT_FOUND:  could not find registered platform with id: 0x1116ff910\n\t [[{{node StatefulPartitionedCall}}]]\n\t [[gradient_tape/model_3/model_2/transformer_encoder_block/multi_head_attention/attention_output/add/Reshape/_84]]\n  (1) NOT_FOUND:  could not find registered platform with id: 0x1116ff910\n\t [[{{node StatefulPartitionedCall}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_62827]"
     ]
    }
   ],
   "source": [
    "clip.compile(optimizer=optimizer, loss=clip_loss_test, metrics=metrics)\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "history = clip.fit(\n",
    "    x = train_generator,\n",
    "    validation_data = val_generator,\n",
    "    epochs=EPOCHS,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
